{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, transformers\n",
    "import nltk\n",
    "import sklearn\n",
    "import gzip, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this to wherever you locally downloaded the data\n",
    "data_base_path = './data/newsroom-release/release/'\n",
    "\n",
    "train_path = data_base_path + 'train.jsonl.gz'\n",
    "validation_path = data_base_path + 'dev.jsonl.gz'\n",
    "test_path = data_base_path + 'dev.jsonl.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsroomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, batch_size, path):\n",
    "        self.batch_size = batch_size\n",
    "        self.file = gzip.open(path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.load_data()\n",
    "\n",
    "    \n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        \n",
    "        for ln in self.file:\n",
    "            if len(data) < self.batch_size:\n",
    "                obj = json.loads(ln)\n",
    "                data.append(obj)\n",
    "            else:\n",
    "                return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is too big to load to memory - create minibatches and parallelize loading with DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = NewsroomDataset(100, train_path)\n",
    "trainloader = torch.utils.data.DataLoader(train_dset)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get batch for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>archive</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>compression</th>\n",
       "      <th>coverage</th>\n",
       "      <th>density</th>\n",
       "      <th>compression_bin</th>\n",
       "      <th>coverage_bin</th>\n",
       "      <th>density_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[http://www.nytimes.com/2006/06/04/sports/socc...</td>\n",
       "      <td>[http://web.archive.org/web/20060618204254id_/...</td>\n",
       "      <td>[Surge in Racist Mood Raises Concerns on Eve o...</td>\n",
       "      <td>[20060618204254]</td>\n",
       "      <td>[HAMBURG, Germany, June 3 Â— As he left the soc...</td>\n",
       "      <td>[A surge in discriminatory behavior toward bla...</td>\n",
       "      <td>[tensor(137.4706, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "      <td>[tensor(7.8235, dtype=torch.float64)]</td>\n",
       "      <td>[high]</td>\n",
       "      <td>[high]</td>\n",
       "      <td>[mixed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[http://www.nytimes.com/2005/12/24/politics/24...</td>\n",
       "      <td>[http://web.archive.org/web/20060620043011id_/...</td>\n",
       "      <td>[Spy Agency Mined Vast Data Trove, Officials R...</td>\n",
       "      <td>[20060620043011]</td>\n",
       "      <td>[WASHINGTON, Dec. 23 - The National Security A...</td>\n",
       "      <td>[The volume of information harvested, without ...</td>\n",
       "      <td>[tensor(33.6364, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(0.9091, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(4.7273, dtype=torch.float64)]</td>\n",
       "      <td>[medium]</td>\n",
       "      <td>[medium]</td>\n",
       "      <td>[mixed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[http://www.nytimes.com/2006/04/23/business/yo...</td>\n",
       "      <td>[http://web.archive.org/web/20060909062911id_/...</td>\n",
       "      <td>[Investors vs. Pfizer: Guess Who Has the Guns?]</td>\n",
       "      <td>[20060909062911]</td>\n",
       "      <td>[IF outsized executive pay has indeed become a...</td>\n",
       "      <td>[The battle between Pfizer Inc.'s investors an...</td>\n",
       "      <td>[tensor(33.8800, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(1., dtype=torch.float64)]</td>\n",
       "      <td>[tensor(11.7200, dtype=torch.float64)]</td>\n",
       "      <td>[medium]</td>\n",
       "      <td>[high]</td>\n",
       "      <td>[extractive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[http://www.nydailynews.com/archives/gossip/19...</td>\n",
       "      <td>[http://web.archive.org/web/20080313232743id_/...</td>\n",
       "      <td>[REX FLEXED PECS FOR SKIN PICS]</td>\n",
       "      <td>[20080313232743]</td>\n",
       "      <td>[BY A.J. BENZA &amp; MICHAEL LEWITTES\\n\\nIf Simon ...</td>\n",
       "      <td>[If Simon Rex looks a little familiar, it may ...</td>\n",
       "      <td>[tensor(11.8941, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(0.9882, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(38.9882, dtype=torch.float64)]</td>\n",
       "      <td>[low]</td>\n",
       "      <td>[high]</td>\n",
       "      <td>[extractive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[http://www.nydailynews.com/archives/entertain...</td>\n",
       "      <td>[http://web.archive.org/web/20080314003027id_/...</td>\n",
       "      <td>[POPEYE-WORTHY PIE. PHYLLO DOUGH WRAPS SPINACH...</td>\n",
       "      <td>[20080314003027]</td>\n",
       "      <td>[Spinach has terrorized generations of veggie-...</td>\n",
       "      <td>[POPEYE-WORTHY PIE. PHYLLO DOUGH WRAPS SPINACH...</td>\n",
       "      <td>[tensor(3.9326, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(0.9213, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(36.6292, dtype=torch.float64)]</td>\n",
       "      <td>[low]</td>\n",
       "      <td>[medium]</td>\n",
       "      <td>[extractive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[http://www.nytimes.com/1982/01/06/books/the-p...</td>\n",
       "      <td>[http://web.archive.org/web/20131114095011id_/...</td>\n",
       "      <td>[THE POP LIFE - NYTimes.com]</td>\n",
       "      <td>[20131114095011]</td>\n",
       "      <td>[THE worst concert tragedy in the history of r...</td>\n",
       "      <td>[THE worst concert tragedy in the history of r...</td>\n",
       "      <td>[tensor(4.2846, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(0.9921, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(93.6798, dtype=torch.float64)]</td>\n",
       "      <td>[low]</td>\n",
       "      <td>[high]</td>\n",
       "      <td>[extractive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[http://www.msnbc.com/all/roadmap-financial-re...</td>\n",
       "      <td>[http://web.archive.org/web/20131114223718id_/...</td>\n",
       "      <td>[A 'roadmap' for financial reform]</td>\n",
       "      <td>[20131114223718]</td>\n",
       "      <td>[The sweeping financial reform law known as Do...</td>\n",
       "      <td>[Financial reform still has a long way to go, ...</td>\n",
       "      <td>[tensor(45., dtype=torch.float64)]</td>\n",
       "      <td>[tensor(0.8571, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(1.8095, dtype=torch.float64)]</td>\n",
       "      <td>[high]</td>\n",
       "      <td>[medium]</td>\n",
       "      <td>[mixed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[http://www.theguardian.com/artanddesign/2012/...</td>\n",
       "      <td>[http://web.archive.org/web/20131115220701id_/...</td>\n",
       "      <td>[Mind over mattress: Yoko Ono remembers the be...</td>\n",
       "      <td>[20131115220701]</td>\n",
       "      <td>[Reading this on mobile? Watch the bed-in vide...</td>\n",
       "      <td>[In 1969, Ono and John Lennon took to their be...</td>\n",
       "      <td>[tensor(8.6000, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(0.6400, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(1.2000, dtype=torch.float64)]</td>\n",
       "      <td>[low]</td>\n",
       "      <td>[low]</td>\n",
       "      <td>[abstractive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[http://www.bostonglobe.com/arts/movies/2013/1...</td>\n",
       "      <td>[http://web.archive.org/web/20131121001136id_/...</td>\n",
       "      <td>[Taken aback by modern-day time travel]</td>\n",
       "      <td>[20131121001136]</td>\n",
       "      <td>[Has time travel in the movies gotten easier o...</td>\n",
       "      <td>[Has time travel in the movies gotten easier o...</td>\n",
       "      <td>[tensor(3.8207, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(0.9724, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(42.2414, dtype=torch.float64)]</td>\n",
       "      <td>[low]</td>\n",
       "      <td>[high]</td>\n",
       "      <td>[extractive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[http://www.bostonglobe.com/arts/music/2013/12...</td>\n",
       "      <td>[http://web.archive.org/web/20131207071438id_/...</td>\n",
       "      <td>[WEEK AHEAD: FOLK, WORLD &amp; COUNTRY]</td>\n",
       "      <td>[20131207071438]</td>\n",
       "      <td>[PINK If you missed Pinkâ€™s high-flying act the...</td>\n",
       "      <td>[CHILDSPLAY This fiddle supergroup not only fe...</td>\n",
       "      <td>[tensor(6.8462, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(0.9941, dtype=torch.float64)]</td>\n",
       "      <td>[tensor(86.5325, dtype=torch.float64)]</td>\n",
       "      <td>[low]</td>\n",
       "      <td>[high]</td>\n",
       "      <td>[extractive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "0   [http://www.nytimes.com/2006/06/04/sports/socc...   \n",
       "1   [http://www.nytimes.com/2005/12/24/politics/24...   \n",
       "2   [http://www.nytimes.com/2006/04/23/business/yo...   \n",
       "3   [http://www.nydailynews.com/archives/gossip/19...   \n",
       "4   [http://www.nydailynews.com/archives/entertain...   \n",
       "..                                                ...   \n",
       "95  [http://www.nytimes.com/1982/01/06/books/the-p...   \n",
       "96  [http://www.msnbc.com/all/roadmap-financial-re...   \n",
       "97  [http://www.theguardian.com/artanddesign/2012/...   \n",
       "98  [http://www.bostonglobe.com/arts/movies/2013/1...   \n",
       "99  [http://www.bostonglobe.com/arts/music/2013/12...   \n",
       "\n",
       "                                              archive  \\\n",
       "0   [http://web.archive.org/web/20060618204254id_/...   \n",
       "1   [http://web.archive.org/web/20060620043011id_/...   \n",
       "2   [http://web.archive.org/web/20060909062911id_/...   \n",
       "3   [http://web.archive.org/web/20080313232743id_/...   \n",
       "4   [http://web.archive.org/web/20080314003027id_/...   \n",
       "..                                                ...   \n",
       "95  [http://web.archive.org/web/20131114095011id_/...   \n",
       "96  [http://web.archive.org/web/20131114223718id_/...   \n",
       "97  [http://web.archive.org/web/20131115220701id_/...   \n",
       "98  [http://web.archive.org/web/20131121001136id_/...   \n",
       "99  [http://web.archive.org/web/20131207071438id_/...   \n",
       "\n",
       "                                                title              date  \\\n",
       "0   [Surge in Racist Mood Raises Concerns on Eve o...  [20060618204254]   \n",
       "1   [Spy Agency Mined Vast Data Trove, Officials R...  [20060620043011]   \n",
       "2     [Investors vs. Pfizer: Guess Who Has the Guns?]  [20060909062911]   \n",
       "3                     [REX FLEXED PECS FOR SKIN PICS]  [20080313232743]   \n",
       "4   [POPEYE-WORTHY PIE. PHYLLO DOUGH WRAPS SPINACH...  [20080314003027]   \n",
       "..                                                ...               ...   \n",
       "95                       [THE POP LIFE - NYTimes.com]  [20131114095011]   \n",
       "96                 [A 'roadmap' for financial reform]  [20131114223718]   \n",
       "97  [Mind over mattress: Yoko Ono remembers the be...  [20131115220701]   \n",
       "98            [Taken aback by modern-day time travel]  [20131121001136]   \n",
       "99                [WEEK AHEAD: FOLK, WORLD & COUNTRY]  [20131207071438]   \n",
       "\n",
       "                                                 text  \\\n",
       "0   [HAMBURG, Germany, June 3 Â— As he left the soc...   \n",
       "1   [WASHINGTON, Dec. 23 - The National Security A...   \n",
       "2   [IF outsized executive pay has indeed become a...   \n",
       "3   [BY A.J. BENZA & MICHAEL LEWITTES\\n\\nIf Simon ...   \n",
       "4   [Spinach has terrorized generations of veggie-...   \n",
       "..                                                ...   \n",
       "95  [THE worst concert tragedy in the history of r...   \n",
       "96  [The sweeping financial reform law known as Do...   \n",
       "97  [Reading this on mobile? Watch the bed-in vide...   \n",
       "98  [Has time travel in the movies gotten easier o...   \n",
       "99  [PINK If you missed Pinkâ€™s high-flying act the...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   [A surge in discriminatory behavior toward bla...   \n",
       "1   [The volume of information harvested, without ...   \n",
       "2   [The battle between Pfizer Inc.'s investors an...   \n",
       "3   [If Simon Rex looks a little familiar, it may ...   \n",
       "4   [POPEYE-WORTHY PIE. PHYLLO DOUGH WRAPS SPINACH...   \n",
       "..                                                ...   \n",
       "95  [THE worst concert tragedy in the history of r...   \n",
       "96  [Financial reform still has a long way to go, ...   \n",
       "97  [In 1969, Ono and John Lennon took to their be...   \n",
       "98  [Has time travel in the movies gotten easier o...   \n",
       "99  [CHILDSPLAY This fiddle supergroup not only fe...   \n",
       "\n",
       "                                compression  \\\n",
       "0   [tensor(137.4706, dtype=torch.float64)]   \n",
       "1    [tensor(33.6364, dtype=torch.float64)]   \n",
       "2    [tensor(33.8800, dtype=torch.float64)]   \n",
       "3    [tensor(11.8941, dtype=torch.float64)]   \n",
       "4     [tensor(3.9326, dtype=torch.float64)]   \n",
       "..                                      ...   \n",
       "95    [tensor(4.2846, dtype=torch.float64)]   \n",
       "96       [tensor(45., dtype=torch.float64)]   \n",
       "97    [tensor(8.6000, dtype=torch.float64)]   \n",
       "98    [tensor(3.8207, dtype=torch.float64)]   \n",
       "99    [tensor(6.8462, dtype=torch.float64)]   \n",
       "\n",
       "                                 coverage  \\\n",
       "0       [tensor(1., dtype=torch.float64)]   \n",
       "1   [tensor(0.9091, dtype=torch.float64)]   \n",
       "2       [tensor(1., dtype=torch.float64)]   \n",
       "3   [tensor(0.9882, dtype=torch.float64)]   \n",
       "4   [tensor(0.9213, dtype=torch.float64)]   \n",
       "..                                    ...   \n",
       "95  [tensor(0.9921, dtype=torch.float64)]   \n",
       "96  [tensor(0.8571, dtype=torch.float64)]   \n",
       "97  [tensor(0.6400, dtype=torch.float64)]   \n",
       "98  [tensor(0.9724, dtype=torch.float64)]   \n",
       "99  [tensor(0.9941, dtype=torch.float64)]   \n",
       "\n",
       "                                   density compression_bin coverage_bin  \\\n",
       "0    [tensor(7.8235, dtype=torch.float64)]          [high]       [high]   \n",
       "1    [tensor(4.7273, dtype=torch.float64)]        [medium]     [medium]   \n",
       "2   [tensor(11.7200, dtype=torch.float64)]        [medium]       [high]   \n",
       "3   [tensor(38.9882, dtype=torch.float64)]           [low]       [high]   \n",
       "4   [tensor(36.6292, dtype=torch.float64)]           [low]     [medium]   \n",
       "..                                     ...             ...          ...   \n",
       "95  [tensor(93.6798, dtype=torch.float64)]           [low]       [high]   \n",
       "96   [tensor(1.8095, dtype=torch.float64)]          [high]     [medium]   \n",
       "97   [tensor(1.2000, dtype=torch.float64)]           [low]        [low]   \n",
       "98  [tensor(42.2414, dtype=torch.float64)]           [low]       [high]   \n",
       "99  [tensor(86.5325, dtype=torch.float64)]           [low]       [high]   \n",
       "\n",
       "      density_bin  \n",
       "0         [mixed]  \n",
       "1         [mixed]  \n",
       "2    [extractive]  \n",
       "3    [extractive]  \n",
       "4    [extractive]  \n",
       "..            ...  \n",
       "95   [extractive]  \n",
       "96        [mixed]  \n",
       "97  [abstractive]  \n",
       "98   [extractive]  \n",
       "99   [extractive]  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(next(iter(trainloader)))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dependencies and initialize tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\teemu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from nltk import tokenize\n",
    "from sklearn.cluster import KMeans\n",
    "from operator import itemgetter\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "bert_base_model = BertModel.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split text to sentences, and tokenize sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(sentences):\n",
    "    \"\"\"Tokenizes and preprocesses to sentences\"\"\"\n",
    "    sentences = [tokenize.sent_tokenize(s) for s in sentences][0] # Split to sentences\n",
    "    sentences = [x for x in sentences if len(x) > 2] # Remove too short sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the K-Means clustering with single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train, sample_test = itemgetter('text', 'summary')(next(iter(trainloader))[0])\n",
    "\n",
    "sample_sentences = tokenize_sentences(sample_train)\n",
    "\n",
    "# Tokenize\n",
    "sample_train_tokens = bert_tokenizer(sample_sentences, return_tensors='pt', padding='longest')\n",
    "\n",
    "# Preprocess\n",
    "sample_sentences = np.array(sample_sentences)\n",
    "\n",
    "## Get BERT CLS embeddings\n",
    "model_output = bert_base_model(**sample_train_tokens)\n",
    "pooler_output = model_output.pooler_output.detach().numpy() # Get numpy array\n",
    "\n",
    "# Cluster embeddings to find centroids\n",
    "sample_sentences_test = tokenize_sentences(sample_test)\n",
    "\n",
    "# Choose same amount of centroids than the actual summary has\n",
    "k = len(sample_sentences_test)\n",
    "kmeans = KMeans(n_clusters=k).fit(pooler_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find closest token to the centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_n_summaries(n_summaries, centroids, pooler_outputs, model_outputs: np.ndarray):\n",
    "    \"\"\"Returns n most likely sentences for summarization\"\"\"\n",
    "    \n",
    "    summarizations = []\n",
    "        \n",
    "    for k in centroids: # Go through centroids\n",
    "        indices = [] # Get indices for each pooler output\n",
    "        values = [] # Get distances to the centroid k\n",
    "        \n",
    "        # Go through pooler outputs, and find sentence closest to centroid\n",
    "        for i, sample in enumerate(pooler_outputs):\n",
    "            current_dist = np.linalg.norm(sample - k)\n",
    "            values.append(current_dist)\n",
    "            indices.append(i)\n",
    "\n",
    "        # Sort indices based on values\n",
    "        _, indices = zip(*sorted(zip(values, indices)))\n",
    "        \n",
    "        summarization = model_outputs[indices[:n_summaries]]\n",
    "        summarizations.append(summarization)\n",
    "        \n",
    "    return summarizations\n",
    "\n",
    "centroid = kmeans.cluster_centers_\n",
    "summaries = best_n_summaries(1, centroid, pooler_output, sample_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare found centroid and actual summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summaries: \n",
      "\n",
      "1. In 1971, Tomlinson was working on a program to transfer data files between two or more computers.\n",
      "\n",
      "\n",
      "Actual summary: \n",
      " ['Ray Tomlinson, who with his engineering colleagues at BBN gave the world electronic mail, died on Saturday.']\n"
     ]
    }
   ],
   "source": [
    "def print_top_n_summaries(summaries, test_summary):\n",
    "    print(\"Generated summaries: \\n\")\n",
    "    [print(f\"{i+1}. {summary}\") for i, summary in enumerate(summaries)]\n",
    "    print(f\"\\n\\nActual summary: \\n {test_summary}\")\n",
    "    \n",
    "print_top_n_summaries(summaries, sample_sentences_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
